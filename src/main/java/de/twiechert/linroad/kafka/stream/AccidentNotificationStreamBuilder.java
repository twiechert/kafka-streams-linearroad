package de.twiechert.linroad.kafka.stream;

import de.twiechert.linroad.kafka.core.feeder.DataFeeder;
import de.twiechert.linroad.kafka.LinearRoadKafkaBenchmarkApplication;
import de.twiechert.linroad.kafka.core.FallbackTimestampExtractor;
import de.twiechert.linroad.kafka.core.Util;
import de.twiechert.linroad.kafka.core.feeder.PositionReportHandler;
import de.twiechert.linroad.kafka.core.serde.TupleSerdes;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.JoinWindows;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KStreamBuilder;
import org.apache.kafka.streams.processor.TimestampExtractor;
import org.javatuples.Pair;
import org.javatuples.Quartet;
import org.javatuples.Sextet;
import org.javatuples.Triplet;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.stereotype.Component;

import java.util.Properties;

/**
 * This class notifies drivers about occured accidents if they are close-by according to the LR requirements.
 *
 * @author Tayfun Wiechert <tayfun.wiechert@gmail.com>
 */
@Component
public class AccidentNotificationStreamBuilder extends StreamBuilder {

    private static final String TOPIC = "ACC_NOT";

    private final static Logger logger = (Logger) LoggerFactory
            .getLogger(AccidentNotificationStreamBuilder.class);


    @Autowired
    public AccidentNotificationStreamBuilder(LinearRoadKafkaBenchmarkApplication.Context context, Util util) {
        super(context, util, new TupleSerdes.TripletSerdes<>(), new AccidentDetectionStreamBuilder.ValueSerde());
    }

    @Override
    protected KStream getStream(KStreamBuilder builder) {
        logger.debug("Building stream to notify drivers about accidents");

        /**
         * The trigger for an accident notification is a position report
         * that identifies a vehicle entering a segment 0 to 4 segments upstream of some accident location,
         * but only if q was emitted no earlier than theminute following theminutewhen the accident occurred, and no later than the minute the accident is
         */
        KStream<Pair<Long, Integer>, Sextet<Integer, Integer, Integer, Boolean, Integer, Integer>> positionReports =
                builder.stream(PositionReportHandler.TOPIC);

        KStream<Triplet<Integer, Integer, Boolean>, Long> accidentReports =
                builder.stream(new LatestAverageVelocityStreamBuilder.KeySerde(), new AccidentDetectionStreamBuilder.ValueSerde(), AccidentDetectionStreamBuilder.TOPIC);

        // first transform such that keys are equal -> allows joining
        KStream<Triplet<Integer, Integer, Boolean>, Long> positionReportByExpressWaySegmentDirection = positionReports.map((k, v) -> new KeyValue<>(new Triplet<>(v.getValue1(), v.getValue4(), v.getValue3()), k.getValue0()))
                .through("re-partioning-position");
        // repartitioning is required if an existing stream source is "modified" -> https://groups.google.com/forum/#!topic/confluent-platform/t2N4vr1MxgQ

        // IMPORTANT for joining: , but only if q (position report) was emitted
        // **no** earlier than the minute following them inutew hen the accident occurred.
        // i.e. the accident detection must be "before" up to one second
        accidentReports.join(positionReportByExpressWaySegmentDirection, (value1, value2) -> new Pair<>(value1, value1), JoinWindows.of("accident-notification").before(1))
                .map((k, v) -> new KeyValue<>("", new Quartet<>(1, v.getValue0(), v.getValue1(), k.getValue1())));

        // key -> ""| value -> (Type: 1, Time: t, Emit: t?, Seg: s?)

        return accidentReports;
    }

    @Override
    protected String getOutputTopic() {

        return TOPIC;
    }


    @Override
    public Properties getStreamConfig() {
        Properties properties = new Properties();
        properties.putAll(this.getBaseProperties());
        properties.put(StreamsConfig.TIMESTAMP_EXTRACTOR_CLASS_CONFIG, TimeStampExtractor.class.getName());
        return properties;
    }

    @Override
    protected StreamBuilder.Options getOptions() {
        return new Options("output.csv");
    }



    /**
     * This class is able to extract timestamp from the values generated by this stream.
     * We use a Fallbacktimestamp extractor, because we can only specify one timestamp extractor per job ...
     *
     *
     * @author Tayfun Wiechert <tayfun.wiechert@gmail.com>
     */
    public static class TimeStampExtractor extends FallbackTimestampExtractor implements TimestampExtractor {
        @Override
        public long extractTimestamp(ConsumerRecord<Object, Object> record) {

            return (Long)record.value();
        }
    }
}
